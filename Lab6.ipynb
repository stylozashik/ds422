{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1305e3c8",
   "metadata": {},
   "source": [
    "# Lab VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "68da4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a8899",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd6922",
   "metadata": {},
   "source": [
    "*Tensor is a n-dimensional array, it means that it can have any number of dimensions.NumPy `ndarray` can not be loaded into GPUs. However, `tensor`s can do so.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(4.)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([1, 2, 3, 4, 5.0])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adcff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [3, 4, 5],\n",
    "    [6, 7, 8]\n",
    "])\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ae6efd",
   "metadata": {},
   "source": [
    "*We can use both NumPy stype `shape` or PyTorch specific `size()` function to get the size of the tensor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b619dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.size())\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83edb98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.dtype)\n",
    "print(y.dtype)\n",
    "print(z.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a606991",
   "metadata": {},
   "source": [
    "*PyTorch is perfectly compatible with NumPy. We use `from_numpy()` to create `tensor` from `ndarray`, and use `numpy()` to convert a `tensor` into a `ndarray`. However, converting between them does not change the memory location of them. So be careful.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75493d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(16).reshape(4, 4)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6369ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = torch.from_numpy(n)\n",
    "tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n.dtype)\n",
    "print(tn.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967fa7da",
   "metadata": {},
   "source": [
    "*PyTorch even has NumPy like interface for creating tensors. Common utility functions for creating a `tensor` include `empty`, `ones`, `zeros`, `rand`, `randint`, etc., and their corresponding `empty_like`, `rand_like`, `randint_like`, etc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0ecefb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = torch.empty(2, 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff4276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(3, 6)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.ones(2, 2)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.eye(3, 4)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f10935",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones_like(z, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71616bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0bb791",
   "metadata": {},
   "source": [
    "*Slicing and indexing is similar to NumPy. However, we can use `item` to get the actual value if the tensor has only one item.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "098f09cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(5.)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e58124ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4bf568",
   "metadata": {},
   "source": [
    "*We can use `view` function to reshape a tensor.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f10a0c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 0, 1, 1],\n",
       "        [2, 0, 3, 3],\n",
       "        [4, 3, 4, 3],\n",
       "        [2, 1, 1, 0],\n",
       "        [3, 3, 2, 1]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0, 5, (5, 4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5be6bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 0, 1, 1, 2, 0, 3, 3, 4, 3],\n",
       "        [4, 3, 2, 1, 1, 0, 3, 3, 2, 1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(2, 10)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f06d8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 0, 1, 1, 2],\n",
       "        [0, 3, 3, 4, 3],\n",
       "        [4, 3, 2, 1, 1],\n",
       "        [0, 3, 3, 2, 1]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85585490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 0, 1, 1],\n",
       "        [2, 0, 3, 3],\n",
       "        [4, 3, 4, 3],\n",
       "        [2, 1, 1, 0],\n",
       "        [3, 3, 2, 1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(-1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841dcc8e",
   "metadata": {},
   "source": [
    "*`unsqueeze` can add a new dimension at the specified position.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1584000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(x, 0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056befe5",
   "metadata": {},
   "source": [
    "# Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b8f60d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(5.)\n",
    "w = torch.tensor(2., requires_grad=True)\n",
    "b = torch.tensor(3., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cdad6894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = w*x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6992716",
   "metadata": {},
   "source": [
    "*We can automatically calculate the derivatives of `y` with respect to its parameters which have `requires_grad=True` set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "677ecd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "71093629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dw:  tensor(5.)\n",
      "dy/db:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print('dy/dw: ', w.grad)\n",
    "print('dy/db: ', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875a788",
   "metadata": {},
   "source": [
    "*If you do not want to calculate gradients for some operation, you can use `with torch.no_grad()`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cc3ab51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 0.001\n",
    "    b -= b.grad * 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2c38afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:  tensor(1.9950, requires_grad=True)\n",
      "B:  tensor(2.9990, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('W: ', w)\n",
    "print('B: ', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e4bc92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dw:  tensor(5.)\n",
      "dy/db:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print('dy/dw: ', w.grad)\n",
    "print('dy/db: ', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea61aa5e",
   "metadata": {},
   "source": [
    "*We can clear the gradients using `zero_` function. Any function with a `_` in the end usually  means the operation is performed in-place.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2257f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e755eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dw:  tensor(0.)\n",
      "dy/db:  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print('dy/dw: ', w.grad)\n",
    "print('dy/db: ', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64d91cf",
   "metadata": {},
   "source": [
    "# A Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc01eab",
   "metadata": {},
   "source": [
    "*Preparing `iris` data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b8de8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5e3eda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7d57eed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25d80f",
   "metadata": {},
   "source": [
    "*We will be taking first `3` columns, which are sepal lenght, sepal width, and petal length, as our features, and the last column, which is petal width, as target.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "10a77595",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data[:, :3]\n",
    "y = iris.data[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a8b57cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb93b4",
   "metadata": {},
   "source": [
    "*Next, we create tensors from the `ndarray`. Note that we have changed the shape of the label array. At first, `y` was `0` dimensional. To make it work with matrices, we changed it to `-1x1` dimensional, where `-1` means whatever numebr necessary or left after setting `1` column.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8decfd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3a6e6b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 3])\n",
      "torch.float64\n",
      "torch.Size([150, 1])\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x.dtype)\n",
    "print(y.shape)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aabf0b",
   "metadata": {},
   "source": [
    "*Weight initialization. We initialize a `3x1` matrix as there are `3` features, and a `1x1` bias.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cd2e0223",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand(3, 1, requires_grad=True, dtype=torch.float64)\n",
    "b = torch.rand(1, 1, requires_grad=True, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "24386b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4247],\n",
      "        [0.9717],\n",
      "        [0.6651]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0b8d86fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0009]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2735dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1])\n",
      "torch.float64\n",
      "torch.Size([1, 1])\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(w.shape)\n",
    "print(w.dtype)\n",
    "print(b.shape)\n",
    "print(b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d07b23",
   "metadata": {},
   "source": [
    "*Creating model. Our simple linear model has equation of $w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + b$, which is simply achieved by computing $x\\times W + b$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d252377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "67b92d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(pred, label):\n",
    "    ae = pred - label\n",
    "    return torch.sum(ae * ae) / ae.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "13db47aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Loss  tensor(0.2404, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch  1 : Loss  tensor(0.2255, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch  2 : Loss  tensor(0.2117, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch  3 : Loss  tensor(0.1990, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch  4 : Loss  tensor(0.1871, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch  5 : Loss  tensor(0.1762, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch  6 : Loss  tensor(0.1660, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch  7 : Loss  tensor(0.1566, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch  8 : Loss  tensor(0.1479, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Epoch  9 : Loss  tensor(0.1398, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "for e in range(epochs):\n",
    "    predictions = model(x)\n",
    "    loss = mse(predictions, y)\n",
    "    \n",
    "    print('Epoch ', e, ': Loss ', loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss.backward()\n",
    "        \n",
    "        w -= w.grad * lr\n",
    "        b -= b.grad * lr\n",
    "        \n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac8eee",
   "metadata": {},
   "source": [
    "# Regression Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "91c115f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn.functional import mse_loss\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9b7b5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeTensor:\n",
    "    def __call__(self, sample):\n",
    "        x, y = sample\n",
    "        return torch.from_numpy(x.astype(np.float32)), torch.from_numpy(y.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4d3a7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRISDataset(Dataset):\n",
    "    def __init__(self, transforms=None):\n",
    "        data = load_iris()\n",
    "        self.x = data.data[:, 0:3]\n",
    "        self.y = data.data[:, [3]]\n",
    "        self.n = data.data.shape[0]\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "10aaeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IRISDataset(transforms=MakeTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3ebfacd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.1000, 3.5000, 1.4000]), tensor([0.2000]))"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "7b663ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasampler = SubsetRandomSampler(np.arange(len(dataset)))\n",
    "dataloader = DataLoader(dataset, 32, sampler=datasampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5026b44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 3])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([22, 3])\n",
      "torch.Size([22, 1])\n"
     ]
    }
   ],
   "source": [
    "for xa, ya in dataloader:\n",
    "    print(xa.shape)\n",
    "    print(ya.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "bdbb9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(in_features=3, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "bf5db727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5267, -0.2628,  0.2328]], requires_grad=True)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "61f51079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.5640], requires_grad=True)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6ca90c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.5267, -0.2628,  0.2328]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.5640], requires_grad=True)]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9b3a6b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f44924",
   "metadata": {},
   "source": [
    "Suppose your `epochs=10`, your training data has `10,000` observations, and batch size is `1,000`. Then, then number of weight updates that will take place is `10 * (10,000/1,000)`. It means in each epoch, there will be `10000/1000` or `10` steps. Therefore, in `10` epochs, there will be `100` steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "92452dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "tensor(6.2764, grad_fn=<MseLossBackward>)\n",
      "Epoch  1\n",
      "tensor(5.3186, grad_fn=<MseLossBackward>)\n",
      "Epoch  2\n",
      "tensor(3.7363, grad_fn=<MseLossBackward>)\n",
      "Epoch  3\n",
      "tensor(3.2597, grad_fn=<MseLossBackward>)\n",
      "Epoch  4\n",
      "tensor(2.3804, grad_fn=<MseLossBackward>)\n",
      "Epoch  5\n",
      "tensor(1.7077, grad_fn=<MseLossBackward>)\n",
      "Epoch  6\n",
      "tensor(1.6132, grad_fn=<MseLossBackward>)\n",
      "Epoch  7\n",
      "tensor(1.1950, grad_fn=<MseLossBackward>)\n",
      "Epoch  8\n",
      "tensor(0.8286, grad_fn=<MseLossBackward>)\n",
      "Epoch  9\n",
      "tensor(0.8251, grad_fn=<MseLossBackward>)\n",
      "Epoch  10\n",
      "tensor(0.6117, grad_fn=<MseLossBackward>)\n",
      "Epoch  11\n",
      "tensor(0.5613, grad_fn=<MseLossBackward>)\n",
      "Epoch  12\n",
      "tensor(0.4942, grad_fn=<MseLossBackward>)\n",
      "Epoch  13\n",
      "tensor(0.3717, grad_fn=<MseLossBackward>)\n",
      "Epoch  14\n",
      "tensor(0.3754, grad_fn=<MseLossBackward>)\n",
      "Epoch  15\n",
      "tensor(0.2714, grad_fn=<MseLossBackward>)\n",
      "Epoch  16\n",
      "tensor(0.2096, grad_fn=<MseLossBackward>)\n",
      "Epoch  17\n",
      "tensor(0.2350, grad_fn=<MseLossBackward>)\n",
      "Epoch  18\n",
      "tensor(0.2689, grad_fn=<MseLossBackward>)\n",
      "Epoch  19\n",
      "tensor(0.2475, grad_fn=<MseLossBackward>)\n",
      "Epoch  20\n",
      "tensor(0.2207, grad_fn=<MseLossBackward>)\n",
      "Epoch  21\n",
      "tensor(0.1696, grad_fn=<MseLossBackward>)\n",
      "Epoch  22\n",
      "tensor(0.2083, grad_fn=<MseLossBackward>)\n",
      "Epoch  23\n",
      "tensor(0.1807, grad_fn=<MseLossBackward>)\n",
      "Epoch  24\n",
      "tensor(0.2156, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "\n",
    "for e in range(epochs):\n",
    "    for xb, yb in dataloader:\n",
    "        predictions = model(xb)\n",
    "        loss = mse_loss(predictions, yb)\n",
    "    \n",
    "    print('Epoch ', e)\n",
    "    print(loss)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8dde32",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "799c25f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.nn.functional import relu, softmax, cross_entropy\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d69c951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST('./data/', download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "38893b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "fcd95518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(n, val_fraction=0.2):\n",
    "    nval = int(n * val_fraction)\n",
    "    idx = np.random.permutation(n)\n",
    "    return idx[nval:], idx[:nval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6b668d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx = train_val_split(len(mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "88c2be4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_idx))\n",
    "print(len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "15a62bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "train_loader = DataLoader(mnist, 32, sampler=train_sampler)\n",
    "val_loader = DataLoader(mnist, 32, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "551d0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(28*28, 10)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 784)\n",
    "        output = self.linear(xb)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "42361a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f87033d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.linear.weight.shape)\n",
    "print(model.linear.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "04da545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8c915dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, label):\n",
    "    _, predictions = torch.max(pred, dim=1)\n",
    "    return torch.sum(predictions == label).item() / len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "879c1ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(model, loss_func, bx, by, optimizer, metric=accuracy):\n",
    "    output = model(bx)       \n",
    "    loss = cross_entropy(output, by)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    result = metric(output, by)\n",
    "    return loss.item(), len(bx), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d5f91a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_func, validation_data, optimizer, metric=accuracy):\n",
    "    results = [train_batch(model, loss_func, bx, by, optimizer, metric) for bx, by in validation_data]\n",
    "    losses, lens, results = zip(*results)\n",
    "    total_data = np.sum(lens)\n",
    "    avg_loss = np.sum(np.multiply(losses, lens)) / total_data\n",
    "    avg_result = np.sum(np.multiply(results, lens)) / total_data\n",
    "    \n",
    "    return avg_loss, total_data, avg_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "6b3892f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, epochs, loss_func, optimizer, train, validation, metric=accuracy):\n",
    "    for e in (range(epochs)):\n",
    "        for bx, by in train:\n",
    "            loss, _, _ = train_batch(model, loss_func, bx, by, optimizer, metric)\n",
    "\n",
    "        val_loss, _, val_result = evaluate(model, loss_func, validation, optimizer, metric)\n",
    "        print('Epoch {}/{}: Training Loss: {:.2f}, Validation Loss: {:.2f}, Validation Metric: {:.2f}'.format(e+1, epochs, loss, val_loss, val_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d7ce4815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Training Loss: 1.43, Validation Loss: 1.29, Validation Metric: 0.79\n",
      "Epoch 2/10: Training Loss: 0.94, Validation Loss: 0.93, Validation Metric: 0.82\n",
      "Epoch 3/10: Training Loss: 0.84, Validation Loss: 0.78, Validation Metric: 0.84\n",
      "Epoch 4/10: Training Loss: 0.63, Validation Loss: 0.69, Validation Metric: 0.85\n",
      "Epoch 5/10: Training Loss: 0.75, Validation Loss: 0.63, Validation Metric: 0.85\n",
      "Epoch 6/10: Training Loss: 0.63, Validation Loss: 0.59, Validation Metric: 0.86\n",
      "Epoch 7/10: Training Loss: 0.57, Validation Loss: 0.56, Validation Metric: 0.86\n",
      "Epoch 8/10: Training Loss: 0.67, Validation Loss: 0.54, Validation Metric: 0.87\n",
      "Epoch 9/10: Training Loss: 0.43, Validation Loss: 0.52, Validation Metric: 0.87\n",
      "Epoch 10/10: Training Loss: 0.42, Validation Loss: 0.50, Validation Metric: 0.87\n"
     ]
    }
   ],
   "source": [
    "fit(model, 10, cross_entropy, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8d4bc",
   "metadata": {},
   "source": [
    "# A Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a73212a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128)\n",
    "        self.linear2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, bx):\n",
    "        bx = bx.view(bx.size(0), -1)\n",
    "        output = self.linear1(bx)\n",
    "        output = relu(output)\n",
    "        output = self.linear2(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a9ff6244",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "77e843fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b4f5613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Training Loss: 0.13, Validation Loss: 0.18, Validation Metric: 0.95\n",
      "Epoch 2/10: Training Loss: 0.27, Validation Loss: 0.11, Validation Metric: 0.97\n",
      "Epoch 3/10: Training Loss: 0.01, Validation Loss: 0.08, Validation Metric: 0.98\n",
      "Epoch 4/10: Training Loss: 0.02, Validation Loss: 0.06, Validation Metric: 0.98\n",
      "Epoch 5/10: Training Loss: 0.10, Validation Loss: 0.04, Validation Metric: 0.99\n",
      "Epoch 6/10: Training Loss: 0.15, Validation Loss: 0.04, Validation Metric: 0.99\n",
      "Epoch 7/10: Training Loss: 0.01, Validation Loss: 0.03, Validation Metric: 0.99\n",
      "Epoch 8/10: Training Loss: 0.01, Validation Loss: 0.03, Validation Metric: 0.99\n",
      "Epoch 9/10: Training Loss: 0.05, Validation Loss: 0.02, Validation Metric: 0.99\n",
      "Epoch 10/10: Training Loss: 0.01, Validation Loss: 0.02, Validation Metric: 0.99\n"
     ]
    }
   ],
   "source": [
    "fit(model, 10, cross_entropy, optimizer, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
